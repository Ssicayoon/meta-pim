//! Extract access relations from Polygeist-generated ISL schedules
//!
//! Polygeist exports both schedule trees and access relations when using
//! the --polyhedral-opt pass. This module parses these exports to build
//! AccessInfo structures for dependency analysis.

use isl_rs::{Context, Schedule, UnionMap};
use regex::Regex;
use std::collections::HashMap;
use std::fs;
use std::path::Path;
use std::sync::Arc;

use crate::access_analysis::{
    AccessInfo, AccessMapHandle, ArrayInfo, ContextHandle, DataType, DomainHandle, MemoryLayout,
    ScheduleHandle, StmtAccess,
};
use crate::polymer_access_reader;

/// Extract access information from Polygeist's ISL output
pub struct AccessExtractor {
    ctx: Arc<Context>,
}

impl AccessExtractor {
    pub fn new(ctx: Arc<Context>) -> Self {
        AccessExtractor { ctx }
    }

    /// Extract access info using ground-truth from Polymer's access dump
    ///
    /// This method attempts to load precise access patterns generated by Polymer.
    ///
    /// Polymer generates ground-truth access patterns when using:
    /// `polygeist-opt --polyhedral-opt --use-polyhedral-optimizer=islexternal \
    ///               --islexternal-dump-accesses=<dir>`
    ///
    /// The access file contains:
    /// - Exact domain constraints from polyhedral analysis
    /// - Precise read/write access relations in ISL format
    /// - No pattern guessing or heuristics needed
    ///
    /// # Arguments
    /// * `access_dir` - Directory containing Polymer access dumps
    /// * `function_name` - Function name (default: "__polygeist_outlined_affine_0")
    ///
    /// # Returns
    /// * `Ok((reads, writes))` - Ground-truth ISL UnionMaps
    /// * `Err(_)` - File not found or parsing error (fall back to pattern synthesis)
    pub fn extract_from_polymer_access_dump(
        &self,
        access_dir: &Path,
        function_name: Option<&str>,
    ) -> Result<(UnionMap, UnionMap), String> {
        let fname = function_name.unwrap_or("__polygeist_outlined_affine_0");
        let access_file = access_dir.join(fname);

        // Try to load ground-truth access file
        let polymer_access = polymer_access_reader::read_polymer_access_file(&access_file)?;

        // Convert to ISL UnionMaps
        let (reads, writes) = polymer_access.to_union_maps(&self.ctx)?;

        log::info!(
            "✓ Loaded ground-truth access patterns from Polymer dump: {}",
            access_file.display()
        );
        log::debug!("  Arrays found: {:?}", polymer_access.get_array_names());

        Ok((reads, writes))
    }

    /// Extract access info from Polygeist schedule directory
    ///
    /// Polygeist writes multiple files when using --islexternal-dump-schedules:
    /// - __polygeist_outlined_affine_0: Main schedule
    /// - __polygeist_outlined_affine_0.reads: Read access relations
    /// - __polygeist_outlined_affine_0.writes: Write access relations
    /// - __polygeist_outlined_affine_0.domain: Iteration domains
    pub fn extract_from_polygeist_dir(&self, schedule_dir: &Path) -> Result<AccessInfo, String> {
        // Read the main schedule file
        let schedule_file = schedule_dir.join("__polygeist_outlined_affine_0");
        let schedule_content = fs::read_to_string(&schedule_file)
            .map_err(|e| format!("Failed to read schedule: {}", e))?;

        // Check for access relation files
        let reads_file = schedule_dir.join("__polygeist_outlined_affine_0.reads");
        let writes_file = schedule_dir.join("__polygeist_outlined_affine_0.writes");
        let domain_file = schedule_dir.join("__polygeist_outlined_affine_0.domain");

        // If access files don't exist, try to extract from schedule
        let (read_maps, write_maps, domains) = if reads_file.exists() && writes_file.exists() {
            // Read from separate files
            let reads_content = fs::read_to_string(&reads_file)
                .map_err(|e| format!("Failed to read reads file: {}", e))?;
            let writes_content = fs::read_to_string(&writes_file)
                .map_err(|e| format!("Failed to read writes file: {}", e))?;
            let domain_content = if domain_file.exists() {
                fs::read_to_string(&domain_file).ok()
            } else {
                None
            };

            (
                self.parse_access_relations(&reads_content)?,
                self.parse_access_relations(&writes_content)?,
                domain_content.and_then(|d| self.parse_domains(&d).ok()),
            )
        } else {
            // Extract from schedule content
            self.extract_from_schedule_content(&schedule_content)?
        };

        // Build AccessInfo
        self.build_access_info(read_maps, write_maps, domains, &schedule_content)
    }

    /// Parse access relations from ISL format
    /// Format: { S[i,j] -> A[i,k]; T[i,j,k] -> B[k,j] }
    pub fn parse_access_relations(
        &self,
        content: &str,
    ) -> Result<HashMap<String, Vec<String>>, String> {
        let mut accesses = HashMap::new();

        // Remove comments and whitespace
        let clean_content = content
            .lines()
            .filter(|line| !line.trim().starts_with('#'))
            .collect::<Vec<_>>()
            .join(" ");

        // Parse ISL union map format
        // Match patterns like: S[i,j] -> A[i,k]
        let re = Regex::new(r"(\w+)\[[^\]]*\]\s*->\s*(\w+)\[[^\]]*\]")
            .map_err(|e| format!("Regex error: {}", e))?;

        for cap in re.captures_iter(&clean_content) {
            let stmt_name = cap[1].to_string();
            let array_name = cap[2].to_string();

            accesses
                .entry(stmt_name)
                .or_insert_with(Vec::new)
                .push(array_name);
        }

        Ok(accesses)
    }

    /// Parse iteration domains from ISL format
    pub fn parse_domains(&self, content: &str) -> Result<HashMap<String, String>, String> {
        let mut domains = HashMap::new();

        // Parse ISL union set format
        // Match patterns like: S[i,j] : 0 <= i < N and 0 <= j < M
        let re = Regex::new(r"(\w+)\[([^\]]*)\]\s*:\s*([^;}]+)")
            .map_err(|e| format!("Regex error: {}", e))?;

        for cap in re.captures_iter(content) {
            let stmt_name = cap[1].to_string();
            let domain_constraint = format!("{{ {}[{}] : {} }}", &cap[1], &cap[2], &cap[3]);
            domains.insert(stmt_name, domain_constraint);
        }

        Ok(domains)
    }

    /// Extract access information from schedule content
    /// This is a fallback when separate access files are not available
    fn extract_from_schedule_content(
        &self,
        content: &str,
    ) -> Result<
        (
            HashMap<String, Vec<String>>,    // reads
            HashMap<String, Vec<String>>,    // writes
            Option<HashMap<String, String>>, // domains
        ),
        String,
    > {
        let mut read_accesses = HashMap::new();
        let mut write_accesses = HashMap::new();
        let mut domains = HashMap::new();

        // Look for domain specification
        if let Some(domain_start) = content.find("domain:") {
            let domain_part = &content[domain_start..];
            if let Some(domain_end) = domain_part.find('\n') {
                let domain_line = &domain_part[7..domain_end].trim();
                // Parse domain specification
                if let Ok(parsed_domains) = self.parse_domains(domain_line) {
                    domains = parsed_domains;
                }
            }
        }

        // Look for schedule bands that might contain access information
        // This is heuristic-based as ISL schedule format doesn't always include accesses

        // Pattern 1: Look for comments with access info (some Polygeist versions)
        let comment_re = Regex::new(r"#\s*(\w+):\s*reads\s*\[([^\]]+)\]")
            .map_err(|e| format!("Regex error: {}", e))?;

        for cap in comment_re.captures_iter(content) {
            let stmt_name = cap[1].to_string();
            let arrays: Vec<String> = cap[2]
                .split(',')
                .map(|s| s.trim().to_string())
                .filter(|s| !s.is_empty())
                .collect();
            read_accesses.insert(stmt_name.clone(), arrays);
        }

        let write_comment_re = Regex::new(r"#\s*(\w+):\s*writes\s*\[([^\]]+)\]")
            .map_err(|e| format!("Regex error: {}", e))?;

        for cap in write_comment_re.captures_iter(content) {
            let stmt_name = cap[1].to_string();
            let arrays: Vec<String> = cap[2]
                .split(',')
                .map(|s| s.trim().to_string())
                .filter(|s| !s.is_empty())
                .collect();
            write_accesses.insert(stmt_name, arrays);
        }

        // Pattern 2: Look for filter nodes which indicate statement names
        let filter_re = Regex::new(r#"filter:\s*"[^"]*\{([^}]+)\}"#)
            .map_err(|e| format!("Regex error: {}", e))?;

        for cap in filter_re.captures_iter(content) {
            let filter_content = &cap[1];
            // Extract statement names from filter
            if let Some(stmt_name) = filter_content.split('[').next() {
                let stmt_name = stmt_name.trim().to_string();
                // If we don't have access info, create placeholder
                read_accesses
                    .entry(stmt_name.clone())
                    .or_insert_with(Vec::new);
                write_accesses.entry(stmt_name).or_insert_with(Vec::new);
            }
        }

        Ok((
            read_accesses,
            write_accesses,
            if domains.is_empty() {
                None
            } else {
                Some(domains)
            },
        ))
    }

    /// Build AccessInfo from parsed components
    fn build_access_info(
        &self,
        read_maps: HashMap<String, Vec<String>>,
        write_maps: HashMap<String, Vec<String>>,
        domains: Option<HashMap<String, String>>,
        schedule_content: &str,
    ) -> Result<AccessInfo, String> {
        // Create handles
        let ctx_handle = ContextHandle::new_placeholder();
        let sched_handle = ScheduleHandle::new_placeholder();

        let mut access_info = AccessInfo::new(ctx_handle, sched_handle);

        // Collect all statement names
        let mut all_stmts = std::collections::HashSet::new();
        all_stmts.extend(read_maps.keys().cloned());
        all_stmts.extend(write_maps.keys().cloned());
        if let Some(ref doms) = domains {
            all_stmts.extend(doms.keys().cloned());
        }

        // Create StmtAccess for each statement
        for stmt_name in all_stmts {
            let mut stmt = StmtAccess::new(stmt_name.clone());

            // Set domain if available
            if let Some(ref doms) = domains {
                if let Some(_domain_str) = doms.get(&stmt_name) {
                    // In real implementation, would parse ISL domain
                    stmt.domain = DomainHandle {
                        _inner: Arc::new(()),
                    };
                }
            }

            // Set read accesses
            if let Some(read_arrays) = read_maps.get(&stmt_name) {
                if !read_arrays.is_empty() {
                    // In real implementation, would create proper ISL union map
                    stmt.reads = AccessMapHandle {
                        _inner: Arc::new(()),
                    };

                    // Track arrays
                    for array_name in read_arrays {
                        if !access_info.arrays.contains_key(array_name) {
                            // Infer array info (simplified)
                            let array = self.infer_array_info(array_name, schedule_content);
                            access_info.add_array(array);
                        }
                    }
                }
            }

            // Set write accesses
            if let Some(write_arrays) = write_maps.get(&stmt_name) {
                if !write_arrays.is_empty() {
                    // In real implementation, would create proper ISL union map
                    stmt.writes = AccessMapHandle {
                        _inner: Arc::new(()),
                    };

                    // Track arrays
                    for array_name in write_arrays {
                        if !access_info.arrays.contains_key(array_name) {
                            let array = self.infer_array_info(array_name, schedule_content);
                            access_info.add_array(array);
                        }
                    }
                }
            }

            access_info.add_statement(stmt);
        }

        Ok(access_info)
    }

    /// Infer array information from context (heuristic)
    fn infer_array_info(&self, name: &str, _schedule_content: &str) -> ArrayInfo {
        // Try to infer from name patterns
        let dimensions = if name.len() == 1 {
            // Single letter arrays often 2D (A, B, C for matrices)
            2
        } else if name.contains("vector") || name.contains("vec") {
            1
        } else {
            2 // Default to 2D
        };

        ArrayInfo {
            name: name.to_string(),
            dimensions,
            sizes: vec![None; dimensions],   // Dynamic sizes
            element_type: DataType::Float32, // Default assumption
            layout: MemoryLayout::RowMajor,
        }
    }
}

/// Extract ISL access relations with ground-truth priority
///
/// Workflow:
/// 1. Generate baseline with access dumps:
///    `./scripts/generate_baseline_with_accesses.sh -c kernel.c -k function`
/// 2. Call this function with `access_dump_dir` parameter
/// 3. Falls back to pattern synthesis if ground-truth unavailable
///
/// # Arguments
/// * `ctx` - ISL context
/// * `schedule_content` - ISL schedule string (for fallback pattern detection)
/// * `pattern` - Pattern name (gemm, conv2d, etc.) for fallback synthesis
/// * `access_dump_dir` - Optional path to Polymer access dump directory
///
/// # Returns
/// * `(reads, writes)` - ISL UnionMaps from ground-truth or pattern synthesis
pub fn extract_isl_accesses_for_pattern(
    ctx: &Arc<Context>,
    schedule_content: &str,
    pattern: &str,
) -> Result<(UnionMap, UnionMap), String> {
    extract_isl_accesses_with_fallback(ctx, schedule_content, pattern, None)
}

/// Extract ISL access relations with explicit ground-truth directory
///
/// This is the recommended entry point that supports ground-truth loading.
///
/// Priority Order:
/// 1. Try loading from `access_dump_dir` if provided (GROUND TRUTH)
/// 2. Fall back to pattern synthesis based on `pattern` parameter
///
/// # Example
/// ```no_run
/// use std::sync::Arc;
/// use std::path::Path;
/// use isl_rs::Context;
///
/// let ctx = Arc::new(Context::alloc());
/// let domain_str = "{ S0[i] : 0 <= i < 10 }";
/// let access_str = "{ S0[i] -> A[i] }";
/// // ...
/// // let (reads, writes) = extract_isl_accesses_with_fallback(
/// //     &ctx,
/// //     domain_str,
/// //     access_str,
/// //     None
/// // )?;
/// ```
pub fn extract_isl_accesses_with_fallback(
    ctx: &Arc<Context>,
    schedule_content: &str,
    pattern: &str,
    access_dump_dir: Option<&Path>,
) -> Result<(UnionMap, UnionMap), String> {
    // Try ground-truth from Polymer access dump
    if let Some(access_dir) = access_dump_dir {
        let extractor = AccessExtractor::new(ctx.clone());
        match extractor.extract_from_polymer_access_dump(access_dir, None) {
            Ok((reads, writes)) => {
                log::info!("✅ Using GROUND-TRUTH access patterns from Polymer");
                return Ok((reads, writes));
            }
            Err(e) => {
                log::warn!(
                    "⚠️  Ground-truth access file not found, falling back to pattern synthesis: {}",
                    e
                );
            }
        }
    }

    // Fall back to pattern synthesis (existing logic)
    log::info!("Using pattern synthesis for: {}", pattern);
    match pattern {
        "gemm" | "matmul" => {
            // GEMM pattern: C = A * B
            // S0[i,j] or S0[i0,i1]: C[i,j] = 0 (initialization)
            // S1[i,j,k] or S1[i0,i1,i2]: C[i,j] += A[i,k] * B[k,j] (computation)
            //
            // Access relations format: { Statement[iterators] -> Array[indices] }
            // This matches ISL's standard format used by PPCG and other polyhedral compilers.
            //
            // Detect iterator naming convention from schedule:
            // - Standard: i, j, k
            // - Polygeist: i0, i1, i2
            // Also detect statement name (S0 or S1)

            let (i_var, j_var, k_var) =
                if schedule_content.contains("S0[i0") || schedule_content.contains("S1[i0") {
                    // Polygeist naming: i0, i1, i2
                    ("i0", "i1", "i2")
                } else {
                    // Standard naming: i, j, k
                    ("i", "j", "k")
                };

            // Detect statement name (Polygeist generates S0 for single-statement kernels)
            // Polygeist uses S0 for GEMM, not S1!
            let stmt_name = if schedule_content.contains("S0[") {
                "S0"
            } else if schedule_content.contains("S1[") {
                "S1"
            } else {
                return Err("No GEMM statement found (expected S0 or S1)".to_string());
            };

            // Create read access relations
            // GEMM reads: C[i,j] (for accumulation), A[i,k], B[k,j]
            // Use detected iterator names AND statement name
            let reads_str = format!(
                "{{ {}[{},{},{}] -> C[{},{}]; {}[{},{},{}] -> A[{},{}]; {}[{},{},{}] -> B[{},{}] }}",
                stmt_name, i_var, j_var, k_var,  // Statement iteration space
                i_var, j_var,                     // C[i,j]
                stmt_name, i_var, j_var, k_var,  // Statement iteration space again
                i_var, k_var,                     // A[i,k]
                stmt_name, i_var, j_var, k_var,  // Statement iteration space again
                k_var, j_var                      // B[k,j]
            );
            let reads = UnionMap::read_from_str(ctx, &reads_str);

            // Create write access relations
            // GEMM writes: C[i,j] (accumulation/reduction)
            // Use detected statement name
            let writes_str = format!(
                "{{ {}[{},{},{}] -> C[{},{}] }}",
                stmt_name,
                i_var,
                j_var,
                k_var, // Statement iteration space
                i_var,
                j_var // C[i,j]
            );
            let writes = UnionMap::read_from_str(ctx, &writes_str);

            Ok((reads, writes))
        }
        "conv2d" => {
            // Convolution pattern
            // Output[n,h,w,c] = sum(Input[n,h+kh,w+kw,ic] * Filter[kh,kw,ic,c])
            let reads_str = "{ S[n,h,w,c,kh,kw,ic] -> M[0,n,h+kh,w+kw,ic]; S[n,h,w,c,kh,kw,ic] -> M[1,kh,kw,ic,c] }";
            let writes_str = "{ S[n,h,w,c,kh,kw,ic] -> M[2,n,h,w,c] }";

            let reads = UnionMap::read_from_str(ctx, reads_str);
            let writes = UnionMap::read_from_str(ctx, writes_str);

            Ok((reads, writes))
        }
        "jacobi" | "jacobi-2d" => {
            // Jacobi 2D iteration: A_new[i,j] = (A_old[i-1,j] + A_old[i+1,j] + A_old[i,j-1] + A_old[i,j+1]) / 4
            // Two statements: S0 reads from A_old, S1 writes to A_new
            // Access pattern: S[i,j] reads A[i-1,j], A[i+1,j], A[i,j-1], A[i,j+1], writes A[i,j]

            // Detect iterator naming convention
            let (i_var, j_var) = if schedule_content.contains("i0") {
                ("i0", "i1")
            } else {
                ("i", "j")
            };

            // Jacobi typically uses two arrays (old and new) or in-place with proper sequencing
            // For dependency analysis, we model reads from neighbors and write to center
            let reads_str = format!(
                "{{ S[{},{}] -> A[{}-1,{}]; S[{},{}] -> A[{}+1,{}]; S[{},{}] -> A[{},{}-1]; S[{},{}] -> A[{},{}+1] }}",
                i_var, j_var, i_var, j_var,  // A[i-1,j]
                i_var, j_var, i_var, j_var,  // A[i+1,j]
                i_var, j_var, i_var, j_var,  // A[i,j-1]
                i_var, j_var, i_var, j_var   // A[i,j+1]
            );
            let writes_str = format!("{{ S[{},{}] -> A[{},{}] }}", i_var, j_var, i_var, j_var);

            let reads = UnionMap::read_from_str(ctx, &reads_str);
            let writes = UnionMap::read_from_str(ctx, &writes_str);

            Ok((reads, writes))
        }
        "red-black-sor" | "rb-sor" => {
            // Red-Black SOR: Two-phase iteration
            // Phase 1 (Red): Update red points (i+j even)
            // Phase 2 (Black): Update black points (i+j odd)
            // S0: Red phase, S1: Black phase

            let (i_var, j_var) = if schedule_content.contains("i0") {
                ("i0", "i1")
            } else {
                ("i", "j")
            };

            // Red phase reads black neighbors, writes red points
            // Black phase reads red neighbors, writes black points
            let reads_str = format!(
                "{{ S0[{},{}] -> A[{}-1,{}]; S0[{},{}] -> A[{}+1,{}]; S0[{},{}] -> A[{},{}-1]; S0[{},{}] -> A[{},{}+1]; \
                  S1[{},{}] -> A[{}-1,{}]; S1[{},{}] -> A[{}+1,{}]; S1[{},{}] -> A[{},{}-1]; S1[{},{}] -> A[{},{}+1] }}",
                i_var, j_var, i_var, j_var,
                i_var, j_var, i_var, j_var,
                i_var, j_var, i_var, j_var,
                i_var, j_var, i_var, j_var,
                i_var, j_var, i_var, j_var,
                i_var, j_var, i_var, j_var,
                i_var, j_var, i_var, j_var,
                i_var, j_var, i_var, j_var
            );
            let writes_str = format!(
                "{{ S0[{},{}] -> A[{},{}]; S1[{},{}] -> A[{},{}] }}",
                i_var, j_var, i_var, j_var, i_var, j_var, i_var, j_var
            );

            let reads = UnionMap::read_from_str(ctx, &reads_str);
            let writes = UnionMap::read_from_str(ctx, &writes_str);

            Ok((reads, writes))
        }
        "fft" => {
            // FFT (Fast Fourier Transform): Complex access pattern with bit-reversal and stride
            //
            // FFT typically involves multiple passes (log2(N) passes for N-point FFT):
            // - Pass p: stride = 2^p, groups of 2^(p+1) elements
            // - Each pass performs butterfly operations on pairs of elements
            //
            // Access pattern for pass p:
            // - Reads: A[i], A[i + stride] (butterfly pair)
            // - Writes: A[i], A[i + stride] (in-place update)
            //
            // For a 1D FFT with N points:
            // - Domain: { S[p,i] : 0 <= p < log2(N) and 0 <= i < N and i mod (2*stride) < stride }
            // - Stride for pass p: stride = 2^p
            //
            // We detect FFT patterns by:
            // 1. Multiple passes (p dimension) or single pass with stride pattern
            // 2. Stride-based access patterns (i + stride)
            // 3. Butterfly-like structure (pairs of elements)

            // Detect iterator naming convention
            let (p_var, i_var) = if schedule_content.contains("i0") {
                ("i0", "i1") // Polygeist: i0=pass, i1=index
            } else if schedule_content.contains("p") {
                ("p", "i") // Standard: p=pass, i=index
            } else {
                ("i0", "i1") // Default to Polygeist convention
            };

            // Check if schedule has pass dimension (multi-pass FFT) or single pass
            let has_pass_dim = schedule_content.contains(&format!("{}", p_var))
                && (schedule_content.contains("log2")
                    || schedule_content.contains("pass")
                    || schedule_content.contains("stride"));

            if has_pass_dim {
                // Multi-pass FFT: S[p,i] with stride = 2^p
                // Reads: A[i], A[i + stride] where stride depends on p
                // Note: ISL doesn't support bit-shift in access relations directly
                // We use a simplified model: A[i] and A[i + stride_p]
                // where stride_p is a parameter that varies with p
                // For now, use a constant stride pattern that approximates FFT
                let reads_str = format!(
                    "{{ S[{},{}] -> A[{}]; S[{},{}] -> A[{}+stride] }}",
                    p_var, i_var, i_var, p_var, i_var, i_var
                );
                let writes_str = format!(
                    "{{ S[{},{}] -> A[{}]; S[{},{}] -> A[{}+stride] }}",
                    p_var, i_var, i_var, p_var, i_var, i_var
                );

                let reads = UnionMap::read_from_str(ctx, &reads_str);
                let writes = UnionMap::read_from_str(ctx, &writes_str);

                Ok((reads, writes))
            } else {
                // Single-pass FFT or simplified model
                // Detect stride from schedule constraints or use default stride=1
                let stride = if schedule_content.contains("stride") {
                    // Try to extract stride value (simplified - would need proper parsing)
                    "stride"
                } else {
                    "1" // Default stride for single pass
                };

                let reads_str = format!(
                    "{{ S[{}] -> A[{}]; S[{}] -> A[{}+{}] }}",
                    i_var, i_var, i_var, i_var, stride
                );
                let writes_str = format!(
                    "{{ S[{}] -> A[{}]; S[{}] -> A[{}+{}] }}",
                    i_var, i_var, i_var, i_var, stride
                );

                let reads = UnionMap::read_from_str(ctx, &reads_str);
                let writes = UnionMap::read_from_str(ctx, &writes_str);

                Ok((reads, writes))
            }
        }
        _ => {
            // Default: try to extract from schedule annotations
            extract_from_schedule_annotations(ctx, schedule_content)
        }
    }
}

/// Try to extract access relations from schedule annotations
fn extract_from_schedule_annotations(
    ctx: &Arc<Context>,
    schedule_content: &str,
) -> Result<(UnionMap, UnionMap), String> {
    // Look for access annotations in comments or special markers
    if schedule_content.contains("S0") && schedule_content.contains("S1") {
        // Assume GEMM-like pattern if we see S0 and S1
        extract_isl_accesses_for_pattern(ctx, schedule_content, "gemm")
    } else {
        // Return empty access relations
        let empty_reads = UnionMap::empty_ctx(ctx);
        let empty_writes = UnionMap::empty_ctx(ctx);
        Ok((empty_reads, empty_writes))
    }
}

/// Compute ISL-based dependencies from access information
pub fn compute_isl_dependencies(
    ctx: &Arc<Context>,
    schedule_content: &str,
    _access_info: &AccessInfo,
) -> Result<IslDependencies, String> {
    // Parse the ISL schedule
    let schedule = Schedule::read_from_str(&ctx, schedule_content);

    // Extract access relations based on pattern
    let (reads, writes) = extract_isl_accesses_for_pattern(ctx, schedule_content, "gemm")?;

    // Compute dependencies using ISL flow analysis
    use isl_rs::UnionAccessInfo;

    // Get schedule map
    let schedule_map = schedule.get_map();

    // RAW dependencies
    let raw_info = UnionAccessInfo::from_sink(reads.copy())
        .set_must_source(writes.copy())
        .set_schedule_map(schedule_map.copy());
    let raw_flow = raw_info.compute_flow();
    let raw_deps = raw_flow.get_must_dependence();

    // WAR dependencies
    let war_info = UnionAccessInfo::from_sink(writes.copy())
        .set_may_source(reads.copy())
        .set_schedule_map(schedule_map.copy());
    let war_flow = war_info.compute_flow();
    let war_deps = war_flow.get_may_dependence();

    // WAW dependencies
    let waw_info = UnionAccessInfo::from_sink(writes.copy())
        .set_must_source(writes.copy())
        .set_kill(writes.copy())
        .set_schedule_map(schedule_map);
    let waw_flow = waw_info.compute_flow();
    let waw_deps = waw_flow.get_must_dependence();

    Ok(IslDependencies {
        raw_deps: Some(raw_deps),
        war_deps: Some(war_deps),
        waw_deps: Some(waw_deps),
        schedule: Arc::new(schedule),
    })
}

/// ISL-computed dependencies
pub struct IslDependencies {
    pub raw_deps: Option<UnionMap>,
    pub war_deps: Option<UnionMap>,
    pub waw_deps: Option<UnionMap>,
    pub schedule: Arc<isl_rs::Schedule>,
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_parse_access_relations() {
        let ctx = Arc::new(Context::alloc());
        let extractor = AccessExtractor::new(ctx);

        let content = "{ S0[i,j] -> A[i,j]; S0[i,j] -> B[j,i]; S1[k] -> C[k] }";
        let result = extractor.parse_access_relations(content).unwrap();

        assert!(result.contains_key("S0"));
        assert!(result.contains_key("S1"));
        assert_eq!(result["S0"].len(), 2);
        assert!(result["S0"].contains(&"A".to_string()));
        assert!(result["S0"].contains(&"B".to_string()));
    }

    #[test]
    fn test_parse_domains() {
        let ctx = Arc::new(Context::alloc());
        let extractor = AccessExtractor::new(ctx);

        let content = "{ S0[i,j] : 0 <= i < 100 and 0 <= j < 100 }";
        let result = extractor.parse_domains(content).unwrap();

        assert!(result.contains_key("S0"));
        assert!(result["S0"].contains("0 <= i < 100"));
    }
}
